{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "877201a695895b76"
      },
      "source": [
        "# TriviaQA"
      ],
      "id": "877201a695895b76"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGUwKR1Kbj3s"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/aaronkossler/triviaqa.git"
      ],
      "id": "vGUwKR1Kbj3s"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "9c2051ee80b1ce21"
      },
      "source": [
        "## Import Dataset"
      ],
      "id": "9c2051ee80b1ce21"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mY3ijI6wKRc5"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "pip install datasets"
      ],
      "id": "mY3ijI6wKRc5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "945abe603034f2cc"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "trivia_qa_wikipedia = load_dataset('trivia_qa', name=\"rc.wikipedia\")"
      ],
      "id": "945abe603034f2cc"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7ddbbbf17f8e289a"
      },
      "outputs": [],
      "source": [
        "test = trivia_qa_wikipedia[\"validation\"]"
      ],
      "id": "7ddbbbf17f8e289a"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Tw1vztqOXwBK"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Convert the evaluation set to the desired format\n",
        "data = []\n",
        "for item in test:\n",
        "    answer = {\n",
        "        \"Aliases\": item[\"answer\"][\"aliases\"],\n",
        "        \"MatchedWikiEntityName\": item[\"answer\"][\"matched_wiki_entity_name\"],\n",
        "        \"NormalizedAliases\": item[\"answer\"][\"normalized_aliases\"],\n",
        "        \"NormalizedMatchedWikiEntityName\": item[\"answer\"][\"normalized_matched_wiki_entity_name\"],\n",
        "        \"NormalizedValue\": item[\"answer\"][\"normalized_value\"],\n",
        "        \"Type\": item[\"answer\"][\"type\"],\n",
        "        \"Value\": item[\"answer\"][\"value\"],\n",
        "    }\n",
        "    entity_pages = [\n",
        "        {\n",
        "            \"DocSource\": item[\"entity_pages\"][\"doc_source\"][index],\n",
        "            \"Filename\": item[\"entity_pages\"][\"filename\"][index],\n",
        "            \"Title\": item[\"entity_pages\"][\"title\"][index],\n",
        "        }\n",
        "        for index in range(len(item[\"entity_pages\"][\"filename\"]))\n",
        "    ]\n",
        "    question = item[\"question\"]\n",
        "    question_id = item[\"question_id\"]\n",
        "    question_source = item[\"question_source\"]\n",
        "    search_results = []\n",
        "    data_item = {\n",
        "        \"Answer\": answer,\n",
        "        \"EntityPages\": entity_pages,\n",
        "        \"Question\": question,\n",
        "        \"QuestionId\": question_id,\n",
        "        \"QuestionSource\": question_source,\n",
        "        \"SearchResults\": search_results,\n",
        "    }\n",
        "    data.append(data_item)\n",
        "\n",
        "output = {\n",
        "    \"Data\": data,\n",
        "    \"Domain\": \"Wikipedia\",\n",
        "    \"VerifiedEval\": False,\n",
        "    \"Version\": 1.0,\n",
        "}\n",
        "\n",
        "# Write the output to a JSON file\n",
        "if not os.path.exists(\"triviaqa/sets\"):\n",
        "    os.makedirs(\"triviaqa/sets\")\n",
        "\n",
        "with open(\"triviaqa/sets/evaluation.json\", \"w\") as f:\n",
        "    json.dump(output, f)"
      ],
      "id": "Tw1vztqOXwBK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs4ULjaIE8G2"
      },
      "source": [
        "## Preprocessing"
      ],
      "id": "bs4ULjaIE8G2"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EB3xAinD0l4a"
      },
      "id": "EB3xAinD0l4a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "AdyAHQktf42h"
      },
      "id": "AdyAHQktf42h"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install evaluate\n",
        "!pip install rouge\n",
        "\n",
        "\n",
        "import torch\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import nltk\n",
        "import spacy\n",
        "import string\n",
        "import evaluate  # Bleu\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, T5TokenizerFast\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "4cMuDCWwf7hJ"
      },
      "id": "4cMuDCWwf7hJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameters"
      ],
      "metadata": {
        "id": "DvdnMTODKs2g"
      },
      "id": "DvdnMTODKs2g"
    },
    {
      "cell_type": "code",
      "source": [
        "TOKENIZER = T5TokenizerFast.from_pretrained(\"t5-base\")\n",
        "MODEL = T5ForConditionalGeneration.from_pretrained(\"t5-base\", return_dict=True)\n",
        "MODEL.to(\"cuda\")\n",
        "OPTIMIZER = Adam(MODEL.parameters(), lr=0.00001)\n",
        "Q_LEN = 256   # Question Length\n",
        "T_LEN = 32    # Target Length\n",
        "BATCH_SIZE = 8\n",
        "DEVICE = \"cuda:0\""
      ],
      "metadata": {
        "id": "-gVKwrAtgNty"
      },
      "id": "-gVKwrAtgNty",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting context, question, and answers from the dataset"
      ],
      "metadata": {
        "id": "9tJJmf90K3SY"
      },
      "id": "9tJJmf90K3SY"
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(data):\n",
        "    articles = []\n",
        "\n",
        "    for item in data:\n",
        "        question = item[\"question\"]\n",
        "        answer = item[\"answer\"][\"value\"]\n",
        "\n",
        "        texts = []\n",
        "        for text in item[\"entity_pages\"][\"wiki_context\"]:\n",
        "            texts.append(text)\n",
        "        context = \" \".join(texts)\n",
        "\n",
        "        inputs = {\"context\": context, \"question\": question, \"answer\": answer}\n",
        "        articles.append(inputs)\n",
        "\n",
        "    return articles"
      ],
      "metadata": {
        "id": "2Z57X63igjTa"
      },
      "id": "2Z57X63igjTa",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = prepare_data(trivia_qa_wikipedia[\"train\"])\n",
        "\n",
        "# Create a Dataframe\n",
        "data = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "BtYfK1DHnX5v"
      },
      "id": "BtYfK1DHnX5v",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QA_Dataset(Dataset):\n",
        "    def __init__(self, tokenizer, dataframe, q_len, t_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.q_len = q_len\n",
        "        self.t_len = t_len\n",
        "        self.data = dataframe\n",
        "        self.questions = self.data[\"question\"]\n",
        "        self.context = self.data[\"context\"]\n",
        "        self.answer = self.data['answer']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        question = self.questions[idx]\n",
        "        context = self.context[idx]\n",
        "        answer = self.answer[idx]\n",
        "\n",
        "        question_tokenized = self.tokenizer(question, context, max_length=self.q_len, padding=\"max_length\",\n",
        "                                                    truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
        "        answer_tokenized = self.tokenizer(answer, max_length=self.t_len, padding=\"max_length\",\n",
        "                                          truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
        "\n",
        "        labels = torch.tensor(answer_tokenized[\"input_ids\"], dtype=torch.long)\n",
        "        labels[labels == 0] = -100\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(question_tokenized[\"input_ids\"], dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(question_tokenized[\"attention_mask\"], dtype=torch.long),\n",
        "            \"labels\": labels,\n",
        "            \"decoder_attention_mask\": torch.tensor(answer_tokenized[\"attention_mask\"], dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "0tvU_1PPmoQG"
      },
      "id": "0tvU_1PPmoQG",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "val_data, train_data = train_test_split(data, shuffle=False, train_size=7900)\n",
        "# val_data, train_data = train_test_split(data[:1000], shuffle=False, train_size=100)\n",
        "\n",
        "train_sampler = RandomSampler(train_data.index)\n",
        "val_sampler = RandomSampler(val_data.index)\n",
        "\n",
        "qa_dataset = QA_Dataset(TOKENIZER, data, Q_LEN, T_LEN)\n",
        "\n",
        "train_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
        "val_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=val_sampler)"
      ],
      "metadata": {
        "id": "jdSLEt2Pphut"
      },
      "id": "jdSLEt2Pphut",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = 0\n",
        "val_loss = 0\n",
        "train_batch_count = 0\n",
        "val_batch_count = 0\n",
        "\n",
        "for epoch in range(4):\n",
        "    MODEL.train()\n",
        "    for batch in tqdm(train_loader, desc=\"Training batches\"):\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "        labels = batch[\"labels\"].to(DEVICE)\n",
        "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
        "\n",
        "        outputs = MODEL(\n",
        "                          input_ids=input_ids,\n",
        "                          attention_mask=attention_mask,\n",
        "                          labels=labels,\n",
        "                          decoder_attention_mask=decoder_attention_mask\n",
        "                        )\n",
        "\n",
        "        OPTIMIZER.zero_grad()\n",
        "        outputs.loss.backward()\n",
        "        OPTIMIZER.step()\n",
        "        train_loss += outputs.loss.item()\n",
        "        train_batch_count += 1\n",
        "\n",
        "    #Evaluation\n",
        "    MODEL.eval()\n",
        "    for batch in tqdm(val_loader, desc=\"Validation batches\"):\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "        labels = batch[\"labels\"].to(DEVICE)\n",
        "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
        "\n",
        "        outputs = MODEL(\n",
        "                          input_ids=input_ids,\n",
        "                          attention_mask=attention_mask,\n",
        "                          labels=labels,\n",
        "                          decoder_attention_mask=decoder_attention_mask\n",
        "                        )\n",
        "\n",
        "        OPTIMIZER.zero_grad()\n",
        "        outputs.loss.backward()\n",
        "        OPTIMIZER.step()\n",
        "        val_loss += outputs.loss.item()\n",
        "        val_batch_count += 1\n",
        "\n",
        "    print(f\"{epoch+1}/{2} -> Train loss: {train_loss / train_batch_count}\\tValidation loss: {val_loss/val_batch_count}\")\n",
        "\n",
        "    MODEL.save_pretrained(f\"qa_model-to-batch-{epoch}\")\n",
        "    TOKENIZER.save_pretrained(f\"qa_tokenizer-to-batch-{epoch}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el88H-QWq4BH",
        "outputId": "3a83b76d-5f5f-4d9e-bf90-569e40d7de2a"
      },
      "id": "el88H-QWq4BH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training batches:   8%|â–Š         | 548/6749 [09:35<1:39:21,  1.04it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL.save_pretrained(\"qa_model\")\n",
        "TOKENIZER.save_pretrained(\"qa_tokenizer\")\n",
        "\n",
        "# Saved files\n",
        "\"\"\"('qa_tokenizer/tokenizer_config.json',\n",
        " 'qa_tokenizer/special_tokens_map.json',\n",
        " 'qa_tokenizer/spiece.model',\n",
        "'qa_tokenizer/added_tokens.json',\n",
        "'qa_tokenizer/tokenizer.json')\"\"\""
      ],
      "metadata": {
        "id": "BYTJ_JKGvDpe"
      },
      "id": "BYTJ_JKGvDpe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_answer(context, question, ref_answer=None):\n",
        "    inputs = TOKENIZER(question, context, max_length=Q_LEN, padding=\"max_length\", truncation=True, add_special_tokens=True)\n",
        "\n",
        "    input_ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n",
        "    attention_mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n",
        "\n",
        "    outputs = MODEL.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    predicted_answer = TOKENIZER.decode(outputs.flatten(), skip_special_tokens=True)\n",
        "\n",
        "    if ref_answer:\n",
        "        # Load the Bleu metric\n",
        "        bleu = evaluate.load(\"google_bleu\")\n",
        "        score = bleu.compute(predictions=[predicted_answer],\n",
        "                            references=[ref_answer])\n",
        "\n",
        "        print(\"Context: \\n\", context)\n",
        "        print(\"\\n\")\n",
        "        print(\"Question: \\n\", question)\n",
        "        return {\n",
        "            \"Reference Answer: \": ref_answer,\n",
        "            \"Predicted Answer: \": predicted_answer,\n",
        "            \"BLEU Score: \": score\n",
        "        }\n",
        "    else:\n",
        "        return predicted_answer"
      ],
      "metadata": {
        "id": "3CTw0-GWvEae"
      },
      "id": "3CTw0-GWvEae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "66023a9ebac2aaac"
      },
      "source": [
        "## Model Prediction"
      ],
      "id": "66023a9ebac2aaac"
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing with first Entry\n",
        "entry = test[0]\n",
        "question = entry[\"question\"]\n",
        "answer = entry[\"answer\"][\"value\"]\n",
        "\n",
        "texts = []\n",
        "for text in entry[\"entity_pages\"][\"wiki_context\"]:\n",
        "      texts.append(text)\n",
        "context = \" \".join(texts)\n",
        "\n",
        "predict_answer(context, question, answer)"
      ],
      "metadata": {
        "id": "4VcdS_javLoe"
      },
      "id": "4VcdS_javLoe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = {}\n",
        "for entry in test:\n",
        "    question = entry[\"question\"]\n",
        "\n",
        "    texts = []\n",
        "    for text in entry[\"entity_pages\"][\"wiki_context\"]:\n",
        "          texts.append(text)\n",
        "    context = \" \".join(texts)\n",
        "    predictions[entry[\"question_id\"]] = predict_answer(context, question)"
      ],
      "metadata": {
        "id": "VKf460VDyyKp"
      },
      "id": "VKf460VDyyKp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iyzcxvTSAqK"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"triviaqa/predictions\"):\n",
        "        os.makedirs(\"triviaqa/predictions\")\n",
        "\n",
        "# Convert the dictionary to a JSON string\n",
        "json_string = json.dumps(predictions)\n",
        "\n",
        "# Write the JSON string to a file\n",
        "with open(\"triviaqa/predictions/t5_predictions.json\", \"w\") as f:\n",
        "    f.write(json_string)"
      ],
      "id": "0iyzcxvTSAqK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "c847ecf167dcae10"
      },
      "source": [
        "## Evaluation"
      ],
      "id": "c847ecf167dcae10"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yY5JzsGtcocO"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"./triviaqa\")"
      ],
      "id": "yY5JzsGtcocO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eb6d4a817c179430"
      },
      "outputs": [],
      "source": [
        "from triviaqa.evaluation.triviaqa_evaluation import evaluate_triviaqa\n",
        "from triviaqa.utils.dataset_utils import *\n",
        "from triviaqa.utils.utils import read_json"
      ],
      "id": "eb6d4a817c179430"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78714714f74e8590"
      },
      "outputs": [],
      "source": [
        "dataset_file = 'triviaqa/sets/evaluation.json'\n",
        "prediction_file = 'triviaqa/predictions/t5_predictions.json'\n",
        "\n",
        "expected_version = 1.0\n",
        "dataset_json = read_triviaqa_data(dataset_file)\n",
        "if dataset_json['Version'] != expected_version:\n",
        "    print('Evaluation expects v-{} , but got dataset with v-{}'.format(expected_version,dataset_json['Version']),\n",
        "          file=sys.stderr)\n",
        "key_to_ground_truth = get_key_to_ground_truth(dataset_json)\n",
        "predictions = read_json(prediction_file)\n",
        "eval_dict = evaluate_triviaqa(key_to_ground_truth, predictions)"
      ],
      "id": "78714714f74e8590"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AufvPVweelsS",
        "outputId": "470d0d4e-9f45-486f-b898-021f678c59d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'exact_match': 47.59164268735143, 'f1': 55.40320738832585, 'common': 7993, 'denominator': 7993, 'pred_len': 7993, 'gold_len': 7993}\n"
          ]
        }
      ],
      "source": [
        "print(eval_dict)"
      ],
      "id": "AufvPVweelsS"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}